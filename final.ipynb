{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20545379-1fbf-4bdb-aea8-4ca6049eb9c6",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c8f79c-930f-4594-9668-e27530d64ed7",
   "metadata": {},
   "source": [
    "For this project, I am attempting to create a model that takes line from the movie *Finding Dory* and predicts which character said which line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325ae92-4566-4bdc-beb6-1499373bb794",
   "metadata": {},
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7d4d628-6d2e-4731-a14c-0bd6d21fce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import numpy as np\n",
    "import string\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models, losses, callbacks\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier, BaggingRegressor, BaggingClassifier, RandomForestRegressor, RandomForestClassifier, AdaBoostClassifier, AdaBoostRegressor, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, get_scorer_names, mean_squared_error, r2_score, mean_squared_error, roc_auc_score, ConfusionMatrixDisplay, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3121207d-3725-437d-88f0-a15b4a110da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376985a8-aeae-4e6b-96ba-a31877be67f5",
   "metadata": {},
   "source": [
    "## Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05061b10-c81d-4b12-bd8c-f5e36e6e2959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Young Dory</td>\n",
       "      <td>Hi, I'm Dory. I suffer from short-term remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>Yes!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>That's exactly what you say!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>Okay, okay. We'll pretend to be the other kids...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Ahoy there! Do you wanna play hide and seek?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name                                               line\n",
       "0  Young Dory  Hi, I'm Dory. I suffer from short-term remembe...\n",
       "1       Jenny                                               Yes!\n",
       "2     Charlie                       That's exactly what you say!\n",
       "3       Jenny  Okay, okay. We'll pretend to be the other kids...\n",
       "4     Charlie       Ahoy there! Do you wanna play hide and seek?"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script = pd.read_csv('finding_dory.csv')\n",
    "script.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36cbdb80-7712-4390-9132-f02db95a88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean script\n",
    "def clean_script(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# filter out stopwords and punctuation\n",
    "script['filtered_line'] = script['line'].apply(clean_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a413a2c-4146-40a9-84d7-fa96455daa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of characters: 74\n",
      "Original number of lines: 1284 \n",
      "\n",
      "Number of main characters: 10\n",
      "Number of filtered lines: 1049 \n",
      "\n",
      "['Young Dory' 'Jenny' 'Charlie' 'Dory' 'Marlin' 'Nemo' 'Hank' 'Fluke'\n",
      " 'Destiny' 'Bailey']\n"
     ]
    }
   ],
   "source": [
    "# keep main characters that have over 30 lines\n",
    "line_counts = script['name'].value_counts()\n",
    "main_characters = line_counts[line_counts > 30].index\n",
    "filtered_script = script[script['name'].isin(main_characters)]\n",
    "\n",
    "print('Original number of characters: {}'.format(len(script['name'].unique())))\n",
    "print('Original number of lines: {} \\n'.format(len(script)))\n",
    "print('Number of main characters: {}'.format(len(filtered_script['name'].unique())))\n",
    "print('Number of filtered lines: {} \\n'.format(len(filtered_script)))\n",
    "\n",
    "print(filtered_script['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61ada2d9-7236-49f1-b7b2-1bbdb2cda065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Dory          359\n",
       "Marlin        162\n",
       "Hank          119\n",
       "Destiny        84\n",
       "Nemo           72\n",
       "Bailey         66\n",
       "Charlie        58\n",
       "Jenny          55\n",
       "Young Dory     40\n",
       "Fluke          34\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_script['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a5445-17ae-47e4-8b0d-b97e35415c14",
   "metadata": {},
   "source": [
    "## Using Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17423afe-84b9-4378-bdc0-1e5da376ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorizers\n",
    "unigram_vectorizer = CountVectorizer(binary=True)\n",
    "bigram_vectorizer = CountVectorizer(binary=True, ngram_range=(2,2))\n",
    "trigram_vectorizer = CountVectorizer(binary=True, ngram_range=(3,3))\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f38d445-9bf8-4220-8436-f80b6e9465fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading classifiers\n",
    "logreg = LogisticRegression(solver = 'newton-cg', multi_class = 'multinomial')\n",
    "\n",
    "# Bagging\n",
    "dt = DecisionTreeClassifier()\n",
    "bc = BaggingClassifier(estimator = dt, n_estimators = 50)\n",
    "\n",
    "# Random forest\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 12345)\n",
    "\n",
    "# Gradient boosting\n",
    "gbr = GradientBoostingClassifier(max_depth = 5, n_estimators = 250, random_state = 12345)\n",
    "\n",
    "# AdaBoosting\n",
    "ada = AdaBoostClassifier(estimator = dt, n_estimators = 250, random_state = 12345)\n",
    "\n",
    "# XGBoosting \n",
    "xgb = XGBClassifier(n_estimators = 250, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95f752-73ff-4420-83ac-ecf4978e22d9",
   "metadata": {},
   "source": [
    "## Analysis: Unfiltered Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a356603-d2be-422b-b0e8-5697bd10ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables\n",
    "uni_X = unigram_vectorizer.fit_transform(filtered_script['line'])\n",
    "bi_X = bigram_vectorizer.fit_transform(filtered_script['line'])\n",
    "tri_X = trigram_vectorizer.fit_transform(filtered_script['line'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(filtered_script['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82649503-ca05-4e0e-bbf8-d8d88562fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': logreg,\n",
    "    'Bagging Classifier': bc,\n",
    "    'Random Forest': rf,\n",
    "    'Gradient Boosting': gbr,\n",
    "    'AdaBoosting': ada,\n",
    "    'XGBoosting': xgb}\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "cv_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1c475f5-58a4-48bd-986a-6112edc78932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(models, X, y, cv_folds):\n",
    "    accuracy_scores = []\n",
    "    for model_name, model in models.items():\n",
    "        cv_scores = cross_val_score(model, X, y, cv=cv_folds, scoring = 'accuracy')\n",
    "        accuracy_scores.append({\n",
    "            'model': model_name,\n",
    "            'mean_accuracy_score': np.mean(cv_scores)})\n",
    "    results = pd.DataFrame(accuracy_scores)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4d9d0-004e-41f9-8b0d-ae2165226176",
   "metadata": {},
   "source": [
    "### Comparing models with unigrams, bigrams, and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14a9a456-991b-4e4c-addf-92b868fa7351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.412830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.417628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.430971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.406190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoosting</td>\n",
       "      <td>0.373745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoosting</td>\n",
       "      <td>0.394725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  mean_accuracy_score\n",
       "0  Logistic Regression             0.412830\n",
       "1   Bagging Classifier             0.417628\n",
       "2        Random Forest             0.430971\n",
       "3    Gradient Boosting             0.406190\n",
       "4          AdaBoosting             0.373745\n",
       "5           XGBoosting             0.394725"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(models, uni_X, y, cv_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203efed-97e0-495c-ba50-3548f9738219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(uni_X, y, test_size=0.3, random_state=1000)\n",
    "\n",
    "# Logistic regression\n",
    "# multinomial logit model\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Bagging\n",
    "bc.fit(X_train, y_train)\n",
    "bc_y_pred = bc.predict(X_test)\n",
    "\n",
    "# Random forest\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "# Gradient boosting\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_y_pred = gbr.predict(X_test)\n",
    "\n",
    "# AdaBoosting\n",
    "ada.fit(X_train, y_train)\n",
    "ada_y_pred = ada.predict(X_test)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Comparing models\n",
    "print('Test set Accuracy of Logistic Regression: {:3f}'.format(accuracy_score(y_test, logreg_y_pred)))\n",
    "print('Test set Accuracy of Bagging Classifier: {:3f}'.format(accuracy_score(y_test, bc_y_pred)))\n",
    "print('Test set Accuracy of Random Forest: {:3f}'.format(accuracy_score(y_test, rf_y_pred)))\n",
    "print('Test set Accuracy of Gradient Boosting: {:3f}'.format(accuracy_score(y_test, gbr_y_pred)))\n",
    "print('Test set Accuracy of AdaBoosting: {:3f}'.format(accuracy_score(y_test, ada_y_pred)))\n",
    "print('Test set Accuracy of XGBoosting: {:3f}'.format(accuracy_score(y_test, xgb_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851f5c2-89b8-4501-a354-25b65c2b7247",
   "metadata": {},
   "source": [
    "## Analysis: Filtered Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267e9ee-db8f-4770-9d31-ec0c578cc644",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_X = unigram_vectorizer.fit_transform(filtered_script['filtered_line'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_X, y, test_size=0.3, random_state=1000)\n",
    "\n",
    "# Logistic regression\n",
    "# WRONG: use multinomial logistic regression\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Bagging\n",
    "bc.fit(X_train, y_train)\n",
    "bc_y_pred = bc.predict(X_test)\n",
    "\n",
    "# Random forest\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "# Gradient boosting\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_y_pred = gbr.predict(X_test)\n",
    "\n",
    "# AdaBoosting\n",
    "ada.fit(X_train, y_train)\n",
    "ada_y_pred = ada.predict(X_test)\n",
    "\n",
    "# XG Boosting\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Comparing models\n",
    "print('Test set Accuracy of Logistic Regression: {:3f}'.format(accuracy_score(y_test, logreg_y_pred)))\n",
    "print('Test set Accuracy of Bagging Classifier: {:3f}'.format(accuracy_score(y_test, bc_y_pred)))\n",
    "print('Test set Accuracy of Random Forest: {:3f}'.format(accuracy_score(y_test, rf_y_pred)))\n",
    "print('Test set Accuracy of Gradient Boosting: {:3f}'.format(accuracy_score(y_test, gbr_y_pred)))\n",
    "print('Test set Accuracy of AdaBoosting: {:3f}'.format(accuracy_score(y_test, ada_y_pred)))\n",
    "print('Test set Accuracy of XGBoosting: {:3f}'.format(accuracy_score(y_test, xgb_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a2f135e-9e93-4602-b9ad-cef419573339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.418553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.373718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.381364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.394679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoosting</td>\n",
       "      <td>0.355687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoosting</td>\n",
       "      <td>0.396621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  mean_accuracy_score\n",
       "0  Logistic Regression             0.418553\n",
       "1   Bagging Classifier             0.373718\n",
       "2        Random Forest             0.381364\n",
       "3    Gradient Boosting             0.394679\n",
       "4          AdaBoosting             0.355687\n",
       "5           XGBoosting             0.396621"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_X = unigram_vectorizer.fit_transform(filtered_script['filtered_line'])\n",
    "run_model(models, filtered_X, y, cv_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008ed47-a81f-47da-898d-58f500f47977",
   "metadata": {},
   "source": [
    "## Analysis: Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba87581-808a-4a6d-a211-ded7a34a27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X = tfidf_vectorizer.fit_transform(filtered_script['filtered_line'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_X, y, test_size=0.3, random_state=1000)\n",
    "\n",
    "# Logistic regression\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Bagging\n",
    "bc.fit(X_train, y_train)\n",
    "bc_y_pred = bc.predict(X_test)\n",
    "\n",
    "# Random forest\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "# Gradient boosting\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_y_pred = gbr.predict(X_test)\n",
    "\n",
    "# AdaBoosting\n",
    "ada.fit(X_train, y_train)\n",
    "ada_y_pred = ada.predict(X_test)\n",
    "\n",
    "# XG Boosting\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Comparing models\n",
    "print('Test set Accuracy of Logistic Regression: {:3f}'.format(accuracy_score(y_test, logreg_y_pred)))\n",
    "print('Test set Accuracy of Bagging Classifier: {:3f}'.format(accuracy_score(y_test, bc_y_pred)))\n",
    "print('Test set Accuracy of Random Forest: {:3f}'.format(accuracy_score(y_test, rf_y_pred)))\n",
    "print('Test set Accuracy of Gradient Boosting: {:3f}'.format(accuracy_score(y_test, gbr_y_pred)))\n",
    "print('Test set Accuracy of AdaBoosting: {:3f}'.format(accuracy_score(y_test, ada_y_pred)))\n",
    "print('Test set Accuracy of XGBoosting: {:3f}'.format(accuracy_score(y_test, xgb_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2f813fe-13ab-4f9e-92dd-c1a181666082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.416676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.417619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.412821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.401364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoosting</td>\n",
       "      <td>0.347088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoosting</td>\n",
       "      <td>0.401419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  mean_accuracy_score\n",
       "0  Logistic Regression             0.416676\n",
       "1   Bagging Classifier             0.417619\n",
       "2        Random Forest             0.412821\n",
       "3    Gradient Boosting             0.401364\n",
       "4          AdaBoosting             0.347088\n",
       "5           XGBoosting             0.401419"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_X = tfidf_vectorizer.fit_transform(filtered_script['filtered_line'])\n",
    "run_model(models, tfidf_X, y, cv_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb4518-f1ab-40dd-8fa3-67e08b3216d4",
   "metadata": {},
   "source": [
    "#\n",
    "# GPT Method\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b03df-f5f9-42ff-b719-8f4e28d4a71d",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8dab0-e8f3-457c-b05d-42aa30192cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still not sure if I should update these!!\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 50\n",
    "EMBEDDING_DIM = 256\n",
    "KEY_DIM = 256\n",
    "N_HEADS = 2\n",
    "FEED_FORWARD_DIM = 256\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abbd539-e75f-4400-a892-62ce952ce3f2",
   "metadata": {},
   "source": [
    "## Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98271093-5b72-482e-be8c-34f02b602f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using nltk's tokenizer\n",
    "script['line_tokens'] = script['line'].apply(word_tokenize)\n",
    "# put script tokens into a list\n",
    "mylist = list(script.line_tokens)\n",
    "mylist = [' '.join(x) for x in mylist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002e1a3-ad27-4c5b-b55e-ce8660231206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a Tensorflow Dataset\n",
    "text_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(mylist)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .shuffle(1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b45b01-91e4-47c1-8a77-ad405bfa1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorization layer\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=\"lower\",\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_LEN + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f1c2a-fd8e-401c-8109-cbe158351d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the layer to the training set\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33608e0a-229e-4052-811e-1766c4d5c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some token:word mappings\n",
    "for i, word in enumerate(vocab[:15]):\n",
    "    print(f\"{i}: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1fa9c-d3e4-4821-ba82-3a903293e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an example line from the script and its vector representation\n",
    "example = mylist[110]\n",
    "example_tokenized = vectorize_layer(example)\n",
    "print(example)\n",
    "print(example_tokenized.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf57bfb-825b-4a61-bc55-47c0eef5b477",
   "metadata": {},
   "source": [
    "## Creating the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d155b-1eb5-4dc0-a6c5-ddd28f3175e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set of bigrams\n",
    "def prepare_bigrams(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "train_bigrams = text_ds.map(prepare_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a639dbb-95d7-4014-96d0-d49105765099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set of trigrams\n",
    "def prepare_trigrams(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-2]\n",
    "    y = tokenized_sentences[:, 2:]\n",
    "    return x, y\n",
    "\n",
    "train_trigrams = text_ds.map(prepare_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0dffee-d5bf-47db-877c-fd1d6e5ea221",
   "metadata": {},
   "source": [
    "Showing example input and output for trigram training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff787e-c09b-4a2f-bc3c-acc9a73ea399",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_output = train_trigrams.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f751cb-c01e-4a02-8234-e568afee60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Input\n",
    "example_input_output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e9d25-727e-4ba6-accf-211fd3fd1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Output (shifted by two tokens)\n",
    "example_input_output[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4f1aa-1f1f-440a-8239-a1395b116fb6",
   "metadata": {},
   "source": [
    "## Create causal attention mask function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404d284-f47d-4a56-873a-5a78eee85642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = tf.cast(m, dtype)\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = tf.concat(\n",
    "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "    )\n",
    "    return tf.tile(mask, mult)\n",
    "\n",
    "np.transpose(causal_attention_mask(1, 10, 10, dtype=tf.int32)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19fbfc-6e0a-46d2-bd78-228cfb673033",
   "metadata": {},
   "source": [
    "## Don't know what to do next..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df20d0f-a5bf-411d-a880-b682bf56b82f",
   "metadata": {},
   "source": [
    "run a sequential model \n",
    "- attention head\n",
    "- spit out result of attention head\n",
    "- print result\n",
    "\n",
    "- do the entire model\n",
    "- extract what comes out of the attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921bc521-5f3a-45bf-acf0-8e6c2e45fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
