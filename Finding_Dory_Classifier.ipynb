{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20545379-1fbf-4bdb-aea8-4ca6049eb9c6",
   "metadata": {},
   "source": [
    "# Using Supervised Ensemble Methods to Classify Characters in the Script of *Finding Dory*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c8f79c-930f-4594-9668-e27530d64ed7",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Can machine learning ensemble classification methods—such as Bagging, Random Forest, Gradient Boosting, AdaBoost, and XGBoost—accurately predict which character delivered a given line from the Finding Dory script?\n",
    "\n",
    "This project explores the effectiveness of ensemble classification methods in tackling tasks that rely exclusively on text data. Lines from the Finding Dory script are vectorized to serve as independent variables for the models, with the corresponding characters treated as the dependent variable. By analyzing the performance of these models, this study aims to shed light on the limitations of basic text-based classification approaches and underscore the importance of developing more advanced techniques for linguistic and textual classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325ae92-4566-4bdc-beb6-1499373bb794",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7d4d628-6d2e-4731-a14c-0bd6d21fce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f900ee",
   "metadata": {},
   "source": [
    "Please download the following files from `nltk` if they are not already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3121207d-3725-437d-88f0-a15b4a110da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376985a8-aeae-4e6b-96ba-a31877be67f5",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### The Data\n",
    "\n",
    "The stimuli used in this analysis are lines of dialogue from the script of *Finding Dory* obtained from [Kaggle](https://www.kaggle.com/datasets/ashtrindade/finding-dory-movie-script). The dataset contains two variables:\n",
    "\n",
    "- `name` (`str`): The name of the character associated with the line\n",
    "- `line` (`str`): The dialogue delivered by that character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05061b10-c81d-4b12-bd8c-f5e36e6e2959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Young Dory</td>\n",
       "      <td>Hi, I'm Dory. I suffer from short-term remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>Yes!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>That's exactly what you say!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>Okay, okay. We'll pretend to be the other kids...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Ahoy there! Do you wanna play hide and seek?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name                                               line\n",
       "0  Young Dory  Hi, I'm Dory. I suffer from short-term remembe...\n",
       "1       Jenny                                               Yes!\n",
       "2     Charlie                       That's exactly what you say!\n",
       "3       Jenny  Okay, okay. We'll pretend to be the other kids...\n",
       "4     Charlie       Ahoy there! Do you wanna play hide and seek?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script = pd.read_csv('data/finding_dory.csv')\n",
    "script.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94edefe8",
   "metadata": {},
   "source": [
    "The function `clean_script` pre-processes the text by transforming all letters to lowercase and removing punctuation. To further investigate how pre-processing affects model performance, the `filter_script` function is defined, which removes stopwords from the dialogue.\n",
    "\n",
    "Using these functions, I created two new variables in the dataframe: \n",
    "\n",
    "- `cleaned_line`: line is lowercase, punctuation is removed\n",
    "- `filtered_line`: line is lowercase, punctuation and stopwords are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36cbdb80-7712-4390-9132-f02db95a88b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>line</th>\n",
       "      <th>cleaned_line</th>\n",
       "      <th>filtered_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Young Dory</td>\n",
       "      <td>Hi, I'm Dory. I suffer from short-term remembe...</td>\n",
       "      <td>hi im dory i suffer from shortterm remembery loss</td>\n",
       "      <td>hi im dory suffer shortterm remembery loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>Yes!</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>That's exactly what you say!</td>\n",
       "      <td>thats exactly what you say</td>\n",
       "      <td>thats exactly say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>Okay, okay. We'll pretend to be the other kids...</td>\n",
       "      <td>okay okay well pretend to be the other kids no...</td>\n",
       "      <td>okay okay well pretend kids hi dory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Ahoy there! Do you wanna play hide and seek?</td>\n",
       "      <td>ahoy there do you wanna play hide and seek</td>\n",
       "      <td>ahoy wan na play hide seek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name                                               line  \\\n",
       "0  Young Dory  Hi, I'm Dory. I suffer from short-term remembe...   \n",
       "1       Jenny                                               Yes!   \n",
       "2     Charlie                       That's exactly what you say!   \n",
       "3       Jenny  Okay, okay. We'll pretend to be the other kids...   \n",
       "4     Charlie       Ahoy there! Do you wanna play hide and seek?   \n",
       "\n",
       "                                        cleaned_line  \\\n",
       "0  hi im dory i suffer from shortterm remembery loss   \n",
       "1                                                yes   \n",
       "2                         thats exactly what you say   \n",
       "3  okay okay well pretend to be the other kids no...   \n",
       "4         ahoy there do you wanna play hide and seek   \n",
       "\n",
       "                                filtered_line  \n",
       "0  hi im dory suffer shortterm remembery loss  \n",
       "1                                         yes  \n",
       "2                           thats exactly say  \n",
       "3         okay okay well pretend kids hi dory  \n",
       "4                  ahoy wan na play hide seek  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to clean script\n",
    "def clean_script(text):\n",
    "    lower_text = text.lower()\n",
    "    clean_text = lower_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return clean_text\n",
    "    \n",
    "    \n",
    "def filter_script(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# clean lines\n",
    "script['cleaned_line'] = script['line'].apply(clean_script)\n",
    "\n",
    "# filter out stopwords\n",
    "script['filtered_line'] = script['cleaned_line'].apply(filter_script)\n",
    "script.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe3763b",
   "metadata": {},
   "source": [
    "To simplify the task, the script is further filtered to only include the characters that deliver over 30 lines in the film. However after exploring the data, it seems that \"Dory\" and \"Young Dory\" are listed as two separate characters. I then assign all \"Young Dory\" lines to \"Dory\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a413a2c-4146-40a9-84d7-fa96455daa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dory' 'Jenny' 'Charlie' 'Marlin' 'Nemo' 'Hank' 'Fluke' 'Destiny'\n",
      " 'Bailey']\n"
     ]
    }
   ],
   "source": [
    "# keep main characters that have over 30 lines\n",
    "line_counts = script['name'].value_counts()\n",
    "main_characters = line_counts[line_counts > 30].index\n",
    "filtered_script = script[script['name'].isin(main_characters)]\n",
    "\n",
    "# modify \"Young Dory\" to \"Dory\" lines\n",
    "script['name'] = script['name'].apply(lambda x: 'Dory' if x == 'Young Dory' else x)\n",
    "\n",
    "print(filtered_script['name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e267322",
   "metadata": {},
   "source": [
    "I then explore the resulting dataframe `script`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dc4fc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of characters: 73\n",
      "Original number of lines: 1284 \n",
      "\n",
      "Number of main characters: 9\n",
      "Number of filtered lines: 1049 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original number of characters: {}'.format(len(script['name'].unique())))\n",
    "print('Original number of lines: {} \\n'.format(len(script)))\n",
    "print('Number of main characters: {}'.format(len(filtered_script['name'].unique())))\n",
    "print('Number of filtered lines: {} \\n'.format(len(filtered_script)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61ada2d9-7236-49f1-b7b2-1bbdb2cda065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Dory       399\n",
       "Marlin     162\n",
       "Hank       119\n",
       "Destiny     84\n",
       "Nemo        72\n",
       "Bailey      66\n",
       "Charlie     58\n",
       "Jenny       55\n",
       "Fluke       34\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of lines from each character\n",
    "line_dist = filtered_script['name'].value_counts()\n",
    "line_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5e3c7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing line distribution of each character\n",
    "plt.figure()\n",
    "line_dist.plot(kind = 'bar')\n",
    "plt.xlabel('Character')\n",
    "plt.ylabel('Number of Lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e54a1f",
   "metadata": {},
   "source": [
    "After this process, the total number of characters decreased from $73$ to $9$ characters. $235$ lines have been removed.\n",
    "\n",
    "The distribution of lines among characters is unequal, which is expected since some characters play more prominent roles than others. In an ideal scenario for a classification task, we would aim for a balanced dataset with an equal number of lines per character to ensure fairness and avoid bias. However, for the purposes of this analysis, I have chosen not to further manipulate the data. This decision reflects a preference for preserving the natural distribution, as it provides a more realistic representation of the dataset and aligns with the fact that we naturally have more information about characters with larger roles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a5445-17ae-47e4-8b0d-b97e35415c14",
   "metadata": {},
   "source": [
    "## Using Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01b238",
   "metadata": {},
   "source": [
    "In this project, I explore four types of vectorization methods to convert text data into numerical representations suitable for machine learning. The following code initializes these vectorizers:\n",
    "\n",
    "- `unigram_vectorizer`: A bag-of-words approach that treats each token independently, without considering its surrounding context.\n",
    "\n",
    "- `bigram_vectorizer`: Considers pairs of consecutive tokens (bigrams) to capture short-term contextual relationships.\n",
    "\n",
    "- `trigram_vectorizer`: Extends this concept to sequences of three consecutive tokens (trigrams), providing a broader context.\n",
    "\n",
    "- `tfidf_vectorizer`: Uses Term Frequency-Inverse Document Frequency (TF-IDF) to assign weights to tokens based on their importance. This approach emphasizes unique terms while downweighting common ones, enabling the model to focus on distinguishing features in the text.\n",
    "\n",
    "The motivation for experimenting with varying $n$-gram vectorizers is to examine how different levels of contextual information impact model performance. By including TF-IDF, I aim to evaluate the benefits of weighting tokens by relevance rather than relying solely on raw counts or presence indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17423afe-84b9-4378-bdc0-1e5da376ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize vectorizers\n",
    "unigram_vectorizer = CountVectorizer(binary=True)\n",
    "bigram_vectorizer = CountVectorizer(binary=True, ngram_range=(2,2))\n",
    "trigram_vectorizer = CountVectorizer(binary=True, ngram_range=(3,3))\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7650b2",
   "metadata": {},
   "source": [
    "I then initialize the five ensemble classifiers that will be evaluated.\n",
    "\n",
    "- `Bagging`: Trains multiple decision trees on bootstrapped subsets of the data, then aggregates predictions from multiple models.\n",
    "\n",
    "- `Random Forest`: Similar to bagging, but selects random subsets of features at each split of the tree.\n",
    "\n",
    "- `Gradient Boosting`: Trains decision trees sequentially and corrects residual errors made by previous trees.\n",
    "\n",
    "- `AdaBoosting`: Trains decision trees sequentially and adjusts model weights based on misclassified data points. \n",
    "\n",
    "- `XGBoosting`: An optimized version of Gradient Boosting, which includes enhancements like regularization, parallelization of tree construction, and handles missing data more effectively.\n",
    "\n",
    "All of these models differ in their approach in improving model performance. By comparing these models, we can assess their relative strengths and weaknesses in textual classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f38d445-9bf8-4220-8436-f80b6e9465fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize classifiers\n",
    "# Bagging\n",
    "dt = DecisionTreeClassifier()\n",
    "bc = BaggingClassifier(estimator = dt, n_estimators = 100)\n",
    "\n",
    "# Random forest\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 12345)\n",
    "\n",
    "# Gradient boosting\n",
    "gbr = GradientBoostingClassifier(max_depth = 5, n_estimators = 100, random_state = 12345)\n",
    "\n",
    "# AdaBoosting\n",
    "ada = AdaBoostClassifier(estimator = dt, n_estimators = 100, random_state = 12345)\n",
    "\n",
    "# XGBoosting \n",
    "xgb = XGBClassifier(n_estimators = 100, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95f752-73ff-4420-83ac-ecf4978e22d9",
   "metadata": {},
   "source": [
    "## Analysis: Unfiltered Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a356603-d2be-422b-b0e8-5697bd10ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables\n",
    "uni_X = unigram_vectorizer.fit_transform(filtered_script['line'])\n",
    "bi_X = bigram_vectorizer.fit_transform(filtered_script['line'])\n",
    "tri_X = trigram_vectorizer.fit_transform(filtered_script['line'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(filtered_script['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82649503-ca05-4e0e-bbf8-d8d88562fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': logreg,\n",
    "    'Bagging Classifier': bc,\n",
    "    'Random Forest': rf,\n",
    "    'Gradient Boosting': gbr,\n",
    "    'AdaBoosting': ada,\n",
    "    'XGBoosting': xgb}\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "cv_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1c475f5-58a4-48bd-986a-6112edc78932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(models, X, y, cv_folds):\n",
    "    accuracy_scores = []\n",
    "    for model_name, model in models.items():\n",
    "        cv_scores = cross_val_score(model, X, y, cv=cv_folds, scoring = 'accuracy')\n",
    "        accuracy_scores.append({\n",
    "            'model': model_name,\n",
    "            'mean_accuracy_score': np.mean(cv_scores)})\n",
    "    results = pd.DataFrame(accuracy_scores)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4d9d0-004e-41f9-8b0d-ae2165226176",
   "metadata": {},
   "source": [
    "### Comparing models with unigrams, bigrams, and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14a9a456-991b-4e4c-addf-92b868fa7351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muni_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(models, X, y, cv_folds)\u001b[0m\n\u001b[1;32m      2\u001b[0m accuracy_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 4\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     accuracy_scores\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model_name,\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_accuracy_score\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(cv_scores)})\n\u001b[1;32m      8\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(accuracy_scores)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:169\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    166\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:594\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:605\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    603\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m--> 605\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_model(models, uni_X, y, cv_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203efed-97e0-495c-ba50-3548f9738219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(uni_X, y, test_size=0.3, random_state=1000)\n",
    "\n",
    "# Logistic regression\n",
    "# multinomial logit model\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Bagging\n",
    "bc.fit(X_train, y_train)\n",
    "bc_y_pred = bc.predict(X_test)\n",
    "\n",
    "# Random forest\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "# Gradient boosting\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_y_pred = gbr.predict(X_test)\n",
    "\n",
    "# AdaBoosting\n",
    "ada.fit(X_train, y_train)\n",
    "ada_y_pred = ada.predict(X_test)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Comparing models\n",
    "print('Test set Accuracy of Logistic Regression: {:3f}'.format(accuracy_score(y_test, logreg_y_pred)))\n",
    "print('Test set Accuracy of Bagging Classifier: {:3f}'.format(accuracy_score(y_test, bc_y_pred)))\n",
    "print('Test set Accuracy of Random Forest: {:3f}'.format(accuracy_score(y_test, rf_y_pred)))\n",
    "print('Test set Accuracy of Gradient Boosting: {:3f}'.format(accuracy_score(y_test, gbr_y_pred)))\n",
    "print('Test set Accuracy of AdaBoosting: {:3f}'.format(accuracy_score(y_test, ada_y_pred)))\n",
    "print('Test set Accuracy of XGBoosting: {:3f}'.format(accuracy_score(y_test, xgb_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851f5c2-89b8-4501-a354-25b65c2b7247",
   "metadata": {},
   "source": [
    "## Analysis: Filtered Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267e9ee-db8f-4770-9d31-ec0c578cc644",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_X = unigram_vectorizer.fit_transform(filtered_script['filtered_line'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_X, y, test_size=0.3, random_state=1000)\n",
    "\n",
    "# Logistic regression\n",
    "# WRONG: use multinomial logistic regression\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Bagging\n",
    "bc.fit(X_train, y_train)\n",
    "bc_y_pred = bc.predict(X_test)\n",
    "\n",
    "# Random forest\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "# Gradient boosting\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_y_pred = gbr.predict(X_test)\n",
    "\n",
    "# AdaBoosting\n",
    "ada.fit(X_train, y_train)\n",
    "ada_y_pred = ada.predict(X_test)\n",
    "\n",
    "# XG Boosting\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Comparing models\n",
    "print('Test set Accuracy of Logistic Regression: {:3f}'.format(accuracy_score(y_test, logreg_y_pred)))\n",
    "print('Test set Accuracy of Bagging Classifier: {:3f}'.format(accuracy_score(y_test, bc_y_pred)))\n",
    "print('Test set Accuracy of Random Forest: {:3f}'.format(accuracy_score(y_test, rf_y_pred)))\n",
    "print('Test set Accuracy of Gradient Boosting: {:3f}'.format(accuracy_score(y_test, gbr_y_pred)))\n",
    "print('Test set Accuracy of AdaBoosting: {:3f}'.format(accuracy_score(y_test, ada_y_pred)))\n",
    "print('Test set Accuracy of XGBoosting: {:3f}'.format(accuracy_score(y_test, xgb_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f135e-9e93-4602-b9ad-cef419573339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.418553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.373718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.381364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.394679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoosting</td>\n",
       "      <td>0.355687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoosting</td>\n",
       "      <td>0.396621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  mean_accuracy_score\n",
       "0  Logistic Regression             0.418553\n",
       "1   Bagging Classifier             0.373718\n",
       "2        Random Forest             0.381364\n",
       "3    Gradient Boosting             0.394679\n",
       "4          AdaBoosting             0.355687\n",
       "5           XGBoosting             0.396621"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_X = unigram_vectorizer.fit_transform(filtered_script['filtered_line'])\n",
    "run_model(models, filtered_X, y, cv_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008ed47-a81f-47da-898d-58f500f47977",
   "metadata": {},
   "source": [
    "## Analysis: Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba87581-808a-4a6d-a211-ded7a34a27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X = tfidf_vectorizer.fit_transform(filtered_script['filtered_line'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_X, y, test_size=0.3, random_state=1000)\n",
    "\n",
    "# Logistic regression\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Bagging\n",
    "bc.fit(X_train, y_train)\n",
    "bc_y_pred = bc.predict(X_test)\n",
    "\n",
    "# Random forest\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "# Gradient boosting\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_y_pred = gbr.predict(X_test)\n",
    "\n",
    "# AdaBoosting\n",
    "ada.fit(X_train, y_train)\n",
    "ada_y_pred = ada.predict(X_test)\n",
    "\n",
    "# XG Boosting\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Comparing models\n",
    "print('Test set Accuracy of Logistic Regression: {:3f}'.format(accuracy_score(y_test, logreg_y_pred)))\n",
    "print('Test set Accuracy of Bagging Classifier: {:3f}'.format(accuracy_score(y_test, bc_y_pred)))\n",
    "print('Test set Accuracy of Random Forest: {:3f}'.format(accuracy_score(y_test, rf_y_pred)))\n",
    "print('Test set Accuracy of Gradient Boosting: {:3f}'.format(accuracy_score(y_test, gbr_y_pred)))\n",
    "print('Test set Accuracy of AdaBoosting: {:3f}'.format(accuracy_score(y_test, ada_y_pred)))\n",
    "print('Test set Accuracy of XGBoosting: {:3f}'.format(accuracy_score(y_test, xgb_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f813fe-13ab-4f9e-92dd-c1a181666082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.416676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.417619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.412821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.401364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoosting</td>\n",
       "      <td>0.347088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoosting</td>\n",
       "      <td>0.401419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  mean_accuracy_score\n",
       "0  Logistic Regression             0.416676\n",
       "1   Bagging Classifier             0.417619\n",
       "2        Random Forest             0.412821\n",
       "3    Gradient Boosting             0.401364\n",
       "4          AdaBoosting             0.347088\n",
       "5           XGBoosting             0.401419"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_X = tfidf_vectorizer.fit_transform(filtered_script['filtered_line'])\n",
    "run_model(models, tfidf_X, y, cv_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb4518-f1ab-40dd-8fa3-67e08b3216d4",
   "metadata": {},
   "source": [
    "#\n",
    "# GPT Method\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b03df-f5f9-42ff-b719-8f4e28d4a71d",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8dab0-e8f3-457c-b05d-42aa30192cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still not sure if I should update these!!\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 50\n",
    "EMBEDDING_DIM = 256\n",
    "KEY_DIM = 256\n",
    "N_HEADS = 2\n",
    "FEED_FORWARD_DIM = 256\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abbd539-e75f-4400-a892-62ce952ce3f2",
   "metadata": {},
   "source": [
    "## Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98271093-5b72-482e-be8c-34f02b602f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using nltk's tokenizer\n",
    "script['line_tokens'] = script['line'].apply(word_tokenize)\n",
    "# put script tokens into a list\n",
    "mylist = list(script.line_tokens)\n",
    "mylist = [' '.join(x) for x in mylist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002e1a3-ad27-4c5b-b55e-ce8660231206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a Tensorflow Dataset\n",
    "text_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(mylist)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .shuffle(1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b45b01-91e4-47c1-8a77-ad405bfa1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorization layer\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=\"lower\",\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_LEN + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f1c2a-fd8e-401c-8109-cbe158351d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the layer to the training set\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33608e0a-229e-4052-811e-1766c4d5c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some token:word mappings\n",
    "for i, word in enumerate(vocab[:15]):\n",
    "    print(f\"{i}: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1fa9c-d3e4-4821-ba82-3a903293e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an example line from the script and its vector representation\n",
    "example = mylist[110]\n",
    "example_tokenized = vectorize_layer(example)\n",
    "print(example)\n",
    "print(example_tokenized.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf57bfb-825b-4a61-bc55-47c0eef5b477",
   "metadata": {},
   "source": [
    "## Creating the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d155b-1eb5-4dc0-a6c5-ddd28f3175e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set of bigrams\n",
    "def prepare_bigrams(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "train_bigrams = text_ds.map(prepare_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a639dbb-95d7-4014-96d0-d49105765099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set of trigrams\n",
    "def prepare_trigrams(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-2]\n",
    "    y = tokenized_sentences[:, 2:]\n",
    "    return x, y\n",
    "\n",
    "train_trigrams = text_ds.map(prepare_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0dffee-d5bf-47db-877c-fd1d6e5ea221",
   "metadata": {},
   "source": [
    "Showing example input and output for trigram training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff787e-c09b-4a2f-bc3c-acc9a73ea399",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_output = train_trigrams.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f751cb-c01e-4a02-8234-e568afee60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Input\n",
    "example_input_output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e9d25-727e-4ba6-accf-211fd3fd1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Output (shifted by two tokens)\n",
    "example_input_output[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4f1aa-1f1f-440a-8239-a1395b116fb6",
   "metadata": {},
   "source": [
    "## Create causal attention mask function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404d284-f47d-4a56-873a-5a78eee85642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = tf.cast(m, dtype)\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = tf.concat(\n",
    "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "    )\n",
    "    return tf.tile(mask, mult)\n",
    "\n",
    "np.transpose(causal_attention_mask(1, 10, 10, dtype=tf.int32)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19fbfc-6e0a-46d2-bd78-228cfb673033",
   "metadata": {},
   "source": [
    "## Don't know what to do next..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df20d0f-a5bf-411d-a880-b682bf56b82f",
   "metadata": {},
   "source": [
    "run a sequential model \n",
    "- attention head\n",
    "- spit out result of attention head\n",
    "- print result\n",
    "\n",
    "- do the entire model\n",
    "- extract what comes out of the attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921bc521-5f3a-45bf-acf0-8e6c2e45fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
